

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>core.ppo_jax &mdash; logRASM v1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=5cb08e4e"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            logRASM
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ReadMe.html">Policy Verification in Stochastic Dynamical Systems Using Logarithmic Neural Certificates</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ReadMe.html#what-does-this-code-do">1. What does this code do?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ReadMe.html#run-from-a-docker-container-preferred">2. Run from a Docker container (preferred)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ReadMe.html#installing-from-source">3. Installing from source</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ReadMe.html#running-for-a-single-benchmark-smoke-test">4. Running for a single benchmark (smoke test)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ReadMe.html#reproducing-results-from-the-paper">5. Reproducing results from the paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ReadMe.html#training-policies-with-stable-baselines">6. Training policies with Stable-Baselines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ReadMe.html#overview-of-input-arguments">7. Overview of input arguments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ReadMe.html#rebuilding-the-docker-container">8. Rebuilding the Docker container</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">Code documentation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">logRASM</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">core.ppo_jax</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for core.ppo_jax</h1><div class="highlight"><pre>
<span></span><span class="c1"># This file contains an implementation of the PPO reinforcement algorithm in JAX.</span>
<span class="c1"># The code can be jitted and can leverage GPU acceleration.</span>
<span class="c1"># The implementation is adapted from https://github.com/MyNameIsArko/RL-Flax.</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">flax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">flax.linen</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">optax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">orbax.checkpoint</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow_probability.substrates.jax.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tfp</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">flax</span><span class="w"> </span><span class="kn">import</span> <span class="n">struct</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">flax.training</span><span class="w"> </span><span class="kn">import</span> <span class="n">orbax_utils</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">flax.training.train_state</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainState</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jax</span><span class="w"> </span><span class="kn">import</span> <span class="n">Array</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jax</span><span class="w"> </span><span class="kn">import</span> <span class="n">jit</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jax</span><span class="w"> </span><span class="kn">import</span> <span class="n">value_and_grad</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jax.lax</span><span class="w"> </span><span class="kn">import</span> <span class="n">stop_gradient</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">core.buffer</span><span class="w"> </span><span class="kn">import</span> <span class="n">define_grid</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">core.jax_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLP</span><span class="p">,</span> <span class="n">create_train_state</span><span class="p">,</span> <span class="n">lipschitz_coeff</span><span class="p">,</span> <span class="n">orbax_set_config</span>


<div class="viewcode-block" id="PPOargs">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.PPOargs">[docs]</a>
<span class="nd">@flax</span><span class="o">.</span><span class="n">struct</span><span class="o">.</span><span class="n">dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">PPOargs</span><span class="p">:</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;seed of the experiment&quot;&quot;&quot;</span>
    <span class="n">high_precision</span><span class="p">:</span> <span class="nb">bool</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Toggle for using 64-bit vs. 32-bit in JAX&quot;&quot;&quot;</span>
    <span class="n">layout</span><span class="p">:</span> <span class="nb">int</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;layout argument for the environment&quot;&quot;&quot;</span>
    <span class="n">total_timesteps</span><span class="p">:</span> <span class="nb">int</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;total timesteps of the experiments&quot;&quot;&quot;</span>
    <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;the learning rate of the optimizer&quot;&quot;&quot;</span>
    <span class="n">num_envs</span><span class="p">:</span> <span class="nb">int</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;the number of parallel game environments&quot;&quot;&quot;</span>
    <span class="n">num_steps</span><span class="p">:</span> <span class="nb">int</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;the number of steps to run in each environment per policy rollout&quot;&quot;&quot;</span>
    <span class="n">anneal_lr</span><span class="p">:</span> <span class="nb">bool</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Toggle learning rate annealing for policy and value networks&quot;&quot;&quot;</span>
    <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;the discount factor gamma&quot;&quot;&quot;</span>
    <span class="n">gae_lambda</span><span class="p">:</span> <span class="nb">float</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;the lambda for the general advantage estimation&quot;&quot;&quot;</span>
    <span class="n">num_minibatches</span><span class="p">:</span> <span class="nb">int</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;the number of mini-batches&quot;&quot;&quot;</span>
    <span class="n">update_epochs</span><span class="p">:</span> <span class="nb">int</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;the K epochs to update the policy&quot;&quot;&quot;</span>
    <span class="n">clip_coef</span><span class="p">:</span> <span class="nb">float</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;the surrogate clipping coefficient&quot;&quot;&quot;</span>
    <span class="n">ent_coef</span><span class="p">:</span> <span class="nb">float</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;coefficient of the entropy&quot;&quot;&quot;</span>
    <span class="n">vf_coef</span><span class="p">:</span> <span class="nb">float</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;coefficient of the value function&quot;&quot;&quot;</span>
    <span class="n">max_grad_norm</span><span class="p">:</span> <span class="nb">float</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;the maximum norm for the gradient clipping&quot;&quot;&quot;</span>
    <span class="n">weighted</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">cplip</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">linfty</span><span class="p">:</span> <span class="nb">bool</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;settings for the Lipschitz constant&quot;&quot;&quot;</span>
    <span class="c1"># to be filled in runtime</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">minibatch_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">num_iterations</span><span class="p">:</span> <span class="nb">int</span></div>



<div class="viewcode-block" id="AgentState">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.AgentState">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">AgentState</span><span class="p">(</span><span class="n">TrainState</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Class inherited from the TrainState class from flax. </span>
<span class="sd">    It sets default values for agent functions to make TrainState work in jitted function.</span>
<span class="sd">    &#39;&#39;&#39;</span>    

    <span class="n">actor_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">pytree_node</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">critic_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">pytree_node</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>



<div class="viewcode-block" id="AgentParams">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.AgentParams">[docs]</a>
<span class="nd">@flax</span><span class="o">.</span><span class="n">struct</span><span class="o">.</span><span class="n">dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">AgentParams</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Class storing parameters for the PPO actor-critic. </span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">actor_params</span><span class="p">:</span> <span class="p">{}</span>
    <span class="n">critic_params</span><span class="p">:</span> <span class="p">{}</span></div>



<div class="viewcode-block" id="Storage">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.Storage">[docs]</a>
<span class="nd">@flax</span><span class="o">.</span><span class="n">struct</span><span class="o">.</span><span class="n">dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Storage</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Class storing data collected in episodes (rollouts/simulations in the environment).</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">obs</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span>
    <span class="n">actions</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span>
    <span class="n">logprobs</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span>
    <span class="n">dones</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span>
    <span class="n">values</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span>
    <span class="n">advantages</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span>
    <span class="n">returns</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span>
    <span class="n">rewards</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span></div>



<div class="viewcode-block" id="EpisodeStatistics">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.EpisodeStatistics">[docs]</a>
<span class="nd">@flax</span><span class="o">.</span><span class="n">struct</span><span class="o">.</span><span class="n">dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">EpisodeStatistics</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Class storing statistics of the episode.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">episode_returns</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span>
    <span class="n">episode_lengths</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span>
    <span class="n">returned_episode_returns</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span>
    <span class="n">returned_episode_lengths</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span></div>



<div class="viewcode-block" id="Actor">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.Actor">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Actor</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Actor class.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">action_shape_prod</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">neurons_per_layer</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">activation_func</span><span class="p">:</span> <span class="nb">list</span>

    <span class="nd">@nn</span><span class="o">.</span><span class="n">compact</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Array</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Apply the Actor network.</span>

<span class="sd">        :param x: State.</span>
<span class="sd">        :return:</span>
<span class="sd">           - action_mean: Next state according to the Actor network. </span>
<span class="sd">           - action_logstd: Standard deviation of the normal distribution from which the action will be sampled.</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="n">fnn</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">neurons</span><span class="p">,</span> <span class="n">afun</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neurons_per_layer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span><span class="p">):</span>
            <span class="n">fnn</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="n">linear_layer_init</span><span class="p">(</span><span class="n">neurons</span><span class="p">),</span>
                <span class="n">afun</span>
            <span class="p">]</span>

        <span class="n">action_mean</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">fnn</span> <span class="o">+</span> <span class="p">[</span><span class="n">linear_layer_init</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_shape_prod</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)])(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">actor_logstd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;logstd&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">zeros</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_shape_prod</span><span class="p">))</span>
        <span class="n">action_logstd</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">actor_logstd</span><span class="p">,</span> <span class="n">action_mean</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># Make logstd the same shape as actions</span>
        <span class="k">return</span> <span class="n">action_mean</span><span class="p">,</span> <span class="n">action_logstd</span></div>



<div class="viewcode-block" id="Critic">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.Critic">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Critic</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Critic class.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">neurons_per_layer</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">activation_func</span><span class="p">:</span> <span class="nb">list</span>

    <span class="nd">@nn</span><span class="o">.</span><span class="n">compact</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Array</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Apply the Critic network.</span>

<span class="sd">        :param x: State.</span>
<span class="sd">        :return: Next state according to the Critic network. </span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="n">fnn</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">neurons</span><span class="p">,</span> <span class="n">afun</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neurons_per_layer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span><span class="p">):</span>
            <span class="n">fnn</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="n">linear_layer_init</span><span class="p">(</span><span class="n">neurons</span><span class="p">),</span>
                <span class="n">afun</span>
            <span class="p">]</span>

        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">fnn</span> <span class="o">+</span> <span class="p">[</span><span class="n">linear_layer_init</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)])(</span><span class="n">x</span><span class="p">)</span></div>



<div class="viewcode-block" id="linear_layer_init">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.linear_layer_init">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">linear_layer_init</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">bias_const</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Helper function to quickly declare linear layer with weight and bias initializers.</span>

<span class="sd">    :param features: Number of neurons. </span>
<span class="sd">    :param std: Scale for the orthogonal matrix initializers.</span>
<span class="sd">    :param bias_const: Initialization for the bias. </span>
<span class="sd">    :return: Linear neural network layer.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">kernel_init</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">orthogonal</span><span class="p">(</span><span class="n">std</span><span class="p">),</span>
                     <span class="n">bias_init</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">bias_const</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">layer</span></div>



<div class="viewcode-block" id="get_action_and_value2">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.get_action_and_value2">[docs]</a>
<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_action_and_value2</span><span class="p">(</span>
        <span class="n">agent_state</span><span class="p">:</span> <span class="n">AgentState</span><span class="p">,</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">AgentParams</span><span class="p">,</span>
        <span class="n">obs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">action</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Construct action distribution and return some statistics and the value.</span>

<span class="sd">    :param agent_state: AgentState (flax TrainState) object.</span>
<span class="sd">    :param params: Parameters of the actor and critic networks.</span>
<span class="sd">    :param obs: Input observation. </span>
<span class="sd">    :param action: Input action. </span>
<span class="sd">    :return:</span>
<span class="sd">       - Summed log probabilities corresponding to the action probabilities. </span>
<span class="sd">       - Summed entropies corresponding to the action probabilities. </span>
<span class="sd">       - Values provided by the critic. </span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">action_mean</span><span class="p">,</span> <span class="n">action_logstd</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">actor_fn</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;actor&#39;</span><span class="p">],</span> <span class="n">obs</span><span class="p">)</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">critic_fn</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;critic&#39;</span><span class="p">],</span> <span class="n">obs</span><span class="p">)</span>
    <span class="n">action_std</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">action_logstd</span><span class="p">)</span>

    <span class="n">probs</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">action_mean</span><span class="p">,</span> <span class="n">action_std</span><span class="p">)</span>

    <span class="n">retval1</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">retval2</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">retval3</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">retval1</span><span class="p">,</span> <span class="n">retval2</span><span class="p">,</span> <span class="n">retval3</span></div>



<div class="viewcode-block" id="get_action_and_value">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.get_action_and_value">[docs]</a>
<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_action_and_value</span><span class="p">(</span><span class="n">agent_state</span><span class="p">:</span> <span class="n">AgentState</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">next_done</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">storage</span><span class="p">:</span> <span class="n">Storage</span><span class="p">,</span>
                         <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                         <span class="n">key</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">Array</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Sample an action and update storage.</span>

<span class="sd">    :param agent_state: AgentState (flax TrainState) object.</span>
<span class="sd">    :param next_obs: Next observation.</span>
<span class="sd">    :param next_done: 1 if this is the last step in the episode, 0 otherwise.</span>
<span class="sd">    :param storage: Storage storing data collected in episodes.</span>
<span class="sd">    :param step: Index of the step used to update the storage. </span>
<span class="sd">    :param key: random number generator key</span>
<span class="sd">    :return:</span>
<span class="sd">       - storage: Updated storage.</span>
<span class="sd">       - action: Sampled action.</span>
<span class="sd">       - key: random number generator key</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">action_mean</span><span class="p">,</span> <span class="n">action_logstd</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">actor_fn</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;actor&#39;</span><span class="p">]),</span> <span class="n">next_obs</span><span class="p">)</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">critic_fn</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;critic&#39;</span><span class="p">]),</span> <span class="n">next_obs</span><span class="p">)</span>
    <span class="n">action_std</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">action_logstd</span><span class="p">)</span>

    <span class="c1"># Sample continuous actions from Normal distribution</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">action_mean</span><span class="p">,</span> <span class="n">action_std</span><span class="p">)</span>
    <span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">subkey</span><span class="p">)</span>
    <span class="n">logprob</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
        <span class="n">obs</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">obs</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">next_obs</span><span class="p">),</span>
        <span class="n">dones</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">dones</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">next_done</span><span class="p">),</span>
        <span class="n">actions</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">actions</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">action</span><span class="p">),</span>
        <span class="n">logprobs</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">logprobs</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">logprob</span><span class="p">),</span>
        <span class="n">values</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">storage</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">key</span></div>



<div class="viewcode-block" id="rollout_jax_jit">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.rollout_jax_jit">[docs]</a>
<span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,))</span>  <span class="c1"># Don&#39;t JIT the environment</span>
<span class="k">def</span><span class="w"> </span><span class="nf">rollout_jax_jit</span><span class="p">(</span>
        <span class="n">env</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">PPOargs</span><span class="p">,</span>
        <span class="n">agent_state</span><span class="p">:</span> <span class="n">AgentState</span><span class="p">,</span>
        <span class="n">next_obs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">next_done</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">storage</span><span class="p">:</span> <span class="n">Storage</span><span class="p">,</span>
        <span class="n">action_key</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span>
        <span class="n">env_key</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span>
        <span class="n">steps_since_reset</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Perform a rollout.  (jitted function)</span>

<span class="sd">    :param env: Environment.</span>
<span class="sd">    :param args: Parameters for the PPO pretraining. (Note: these can differ from the global command line arguments)</span>
<span class="sd">    :param agent_state: AgentState (flax TrainState) object.</span>
<span class="sd">    :param next_obs: Next observation.</span>
<span class="sd">    :param next_done: 1 if this is the last step in the episode, 0 otherwise.</span>
<span class="sd">    :param storage: Storage storing data collected in episodes.</span>
<span class="sd">    :param action_key: random number generator key</span>
<span class="sd">    :param env_key: random number generator key</span>
<span class="sd">    :param steps_since_reset: Number of steps since the environment was reset. </span>
<span class="sd">    :return:</span>
<span class="sd">       - next_obs: Next observation.</span>
<span class="sd">       - next_done: 1 if this is the last step in the episode, 0 otherwise.</span>
<span class="sd">       - storage: Storage storing data collected in episodes.</span>
<span class="sd">       - action_key: random number generator key.</span>
<span class="sd">       - env_key: random number generator key.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">rollout_body</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Helper function for rollout, used to allow JAX jitting. </span>

<span class="sd">        :param i: Step index.</span>
<span class="sd">        :param val: tuple containing agent_state, next_obs, next_done, storage, action_key, env_key, steps_since_reset (as in rollout_jax_jit). </span>
<span class="sd">        :return: updated tuple containing agent_state, next_obs, next_done, storage, action_key, env_key, steps_since_reset</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="n">step</span> <span class="o">=</span> <span class="n">i</span>
        <span class="p">(</span><span class="n">agent_state</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">action_key</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">steps_since_reset</span><span class="p">)</span> <span class="o">=</span> <span class="n">val</span>

        <span class="n">storage</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">action_key</span> <span class="o">=</span> <span class="n">get_action_and_value</span><span class="p">(</span><span class="n">agent_state</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">action_key</span><span class="p">)</span>

        <span class="n">next_obs</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">steps_since_reset</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> \
            <span class="n">env</span><span class="o">.</span><span class="n">vstep</span><span class="p">(</span><span class="n">next_obs</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_get</span><span class="p">(</span><span class="n">action</span><span class="p">),</span> <span class="n">steps_since_reset</span><span class="p">)</span>

        <span class="n">next_done</span> <span class="o">=</span> <span class="n">terminated</span> <span class="o">|</span> <span class="n">truncated</span>
        <span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">rewards</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">rewards</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">reward</span><span class="p">))</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">agent_state</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">action_key</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">steps_since_reset</span><span class="p">)</span>

    <span class="n">val</span> <span class="o">=</span> <span class="p">(</span><span class="n">agent_state</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">action_key</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">steps_since_reset</span><span class="p">)</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">fori_loop</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">rollout_body</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
    <span class="p">(</span><span class="n">agent_state</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">action_key</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">steps_since_reset</span><span class="p">)</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">return</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">action_key</span><span class="p">,</span> <span class="n">env_key</span></div>



<div class="viewcode-block" id="rollout_jax">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.rollout_jax">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">rollout_jax</span><span class="p">(</span>
        <span class="n">env</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">PPOargs</span><span class="p">,</span>
        <span class="n">agent_state</span><span class="p">:</span> <span class="n">AgentState</span><span class="p">,</span>
        <span class="n">next_obs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">next_done</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">storage</span><span class="p">:</span> <span class="n">Storage</span><span class="p">,</span>
        <span class="n">action_key</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span>
        <span class="n">env_key</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span>
        <span class="n">steps_since_reset</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Perform a rollout.  (non-jitted function)    </span>

<span class="sd">    :param env: Environment.</span>
<span class="sd">    :param args: Parameters for the PPO pretraining. (Note: these can differ from the global command line arguments)</span>
<span class="sd">    :param agent_state: AgentState (flax TrainState) object.</span>
<span class="sd">    :param next_obs: Next observation.</span>
<span class="sd">    :param next_done: 1 if this is the last step in the episode, 0 otherwise.</span>
<span class="sd">    :param storage: Storage storing data collected in episodes.</span>
<span class="sd">    :param action_key: random number generator key.</span>
<span class="sd">    :param env_key: random number generator key.</span>
<span class="sd">    :param steps_since_reset: Number of steps since the environment was reset. </span>
<span class="sd">    :return:</span>
<span class="sd">       - next_obs: Next observation.</span>
<span class="sd">       - next_done: 1 if this is the last step in the episode, 0 otherwise.</span>
<span class="sd">       - storage: Storage storing data collected in episodes.</span>
<span class="sd">       - action_key: random number generator key.</span>
<span class="sd">       - env_key: random number generator key.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">):</span>
        <span class="n">storage</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">action_key</span> <span class="o">=</span> <span class="n">get_action_and_value</span><span class="p">(</span><span class="n">agent_state</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">action_key</span><span class="p">)</span>

        <span class="n">next_obs</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">steps_since_reset</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> \
            <span class="n">env</span><span class="o">.</span><span class="n">vstep</span><span class="p">(</span><span class="n">next_obs</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_get</span><span class="p">(</span><span class="n">action</span><span class="p">),</span> <span class="n">steps_since_reset</span><span class="p">)</span>

        <span class="n">next_done</span> <span class="o">=</span> <span class="n">terminated</span> <span class="o">|</span> <span class="n">truncated</span>
        <span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">rewards</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">rewards</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">reward</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">action_key</span><span class="p">,</span> <span class="n">env_key</span></div>



<div class="viewcode-block" id="compute_gae_body">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.compute_gae_body">[docs]</a>
<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_gae_body</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Computes the Gradient Advantage Estimator (GAE).</span>

<span class="sd">    :param i: number of remaining steps. </span>
<span class="sd">    :param val: tuple containing PPO arguments, data storage, and GAE.</span>
<span class="sd">    :return: updated tuple containing PPO arguments, data storage and updated GAE.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">lastgaelam</span><span class="p">)</span> <span class="o">=</span> <span class="n">val</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">i</span>

    <span class="n">nextnonterminal</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">storage</span><span class="o">.</span><span class="n">dones</span><span class="p">[</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">nextvalues</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">nextvalues</span> <span class="o">*</span> <span class="n">nextnonterminal</span> <span class="o">-</span> <span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
    <span class="n">lastgaelam</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">gae_lambda</span> <span class="o">*</span> <span class="n">nextnonterminal</span> <span class="o">*</span> <span class="n">lastgaelam</span>
    <span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">advantages</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">lastgaelam</span><span class="p">))</span>

    <span class="n">val</span> <span class="o">=</span> <span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">lastgaelam</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">val</span></div>



<div class="viewcode-block" id="compute_gae_jit">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.compute_gae_jit">[docs]</a>
<span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_gae_jit</span><span class="p">(</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">PPOargs</span><span class="p">,</span>
        <span class="n">agent_state</span><span class="p">:</span> <span class="n">AgentState</span><span class="p">,</span>
        <span class="n">next_obs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">next_done</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">storage</span><span class="p">:</span> <span class="n">Storage</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Computes the Gradient Advantage Estimator (GAE). (jitted function)</span>
<span class="sd">    </span>
<span class="sd">    :param args: Parameters for the PPO pretraining. (Note: these can differ from the global command line arguments)</span>
<span class="sd">    :param agent_state: AgentState (flax TrainState) object.</span>
<span class="sd">    :param next_obs: Next observation.</span>
<span class="sd">    :param next_done: 1 if this is the last step in the episode, 0 otherwise.</span>
<span class="sd">    :param storage: Storage storing data collected in episodes.</span>
<span class="sd">    :return: Updated storage. </span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># Reset advantages values</span>
    <span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">advantages</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span><span class="o">.</span><span class="n">at</span><span class="p">[:]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
    <span class="n">next_value</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">critic_fn</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;critic&#39;</span><span class="p">]),</span> <span class="n">next_obs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

    <span class="c1"># Compute advantage using generalized advantage estimate</span>
    <span class="n">lastgaelam</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># For last step (the num_steps^th entry) in rollout data</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">nextnonterminal</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">next_done</span>
    <span class="n">nextvalues</span> <span class="o">=</span> <span class="n">next_value</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">nextvalues</span> <span class="o">*</span> <span class="n">nextnonterminal</span> <span class="o">-</span> <span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
    <span class="n">lastgaelam</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">gae_lambda</span> <span class="o">*</span> <span class="n">nextnonterminal</span> <span class="o">*</span> <span class="n">lastgaelam</span>
    <span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">advantages</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">lastgaelam</span><span class="p">))</span>

    <span class="c1"># Then work backward</span>
    <span class="n">val</span> <span class="o">=</span> <span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">lastgaelam</span><span class="p">)</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">fori_loop</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">compute_gae_body</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
    <span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">lastgaelam</span><span class="p">)</span> <span class="o">=</span> <span class="n">val</span>

    <span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">returns</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span> <span class="o">+</span> <span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">storage</span></div>



<div class="viewcode-block" id="compute_gae">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.compute_gae">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_gae</span><span class="p">(</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">PPOargs</span><span class="p">,</span>
        <span class="n">agent_state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
        <span class="n">next_obs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">next_done</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">storage</span><span class="p">:</span> <span class="n">Storage</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Computes the Gradient Advantage Estimator (GAE).</span>

<span class="sd">    :param args: Parameters for the PPO pretraining. (Note: these can differ from the global command line arguments)</span>
<span class="sd">    :param agent_state: AgentState (flax TrainState) object.</span>
<span class="sd">    :param next_obs: Next observation.</span>
<span class="sd">    :param next_done: 1 if this is the last step in the episode, 0 otherwise</span>
<span class="sd">    :param storage: Storage storing data collected in episodes.</span>
<span class="sd">    :return: Updated storage. </span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">advantages</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span><span class="o">.</span><span class="n">at</span><span class="p">[:]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
    <span class="n">next_value</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">critic_fn</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;critic&#39;</span><span class="p">]),</span> <span class="n">next_obs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="n">lastgaelam</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="n">args</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">nextnonterminal</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">next_done</span>
            <span class="n">nextvalues</span> <span class="o">=</span> <span class="n">next_value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nextnonterminal</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">storage</span><span class="o">.</span><span class="n">dones</span><span class="p">[</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">nextvalues</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">nextvalues</span> <span class="o">*</span> <span class="n">nextnonterminal</span> <span class="o">-</span> <span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
        <span class="n">lastgaelam</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">gae_lambda</span> <span class="o">*</span> <span class="n">nextnonterminal</span> <span class="o">*</span> <span class="n">lastgaelam</span>
        <span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">advantages</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">lastgaelam</span><span class="p">))</span>
    <span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">returns</span><span class="o">=</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span> <span class="o">+</span> <span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">storage</span></div>



<div class="viewcode-block" id="update_ppo_jit">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.update_ppo_jit">[docs]</a>
<span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,))</span>  <span class="c1"># Don&#39;t JIT the environment</span>
<span class="k">def</span><span class="w"> </span><span class="nf">update_ppo_jit</span><span class="p">(</span>
        <span class="n">env</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">PPOargs</span><span class="p">,</span>
        <span class="n">agent_state</span><span class="p">:</span> <span class="n">AgentState</span><span class="p">,</span>
        <span class="n">storage</span><span class="p">:</span> <span class="n">Storage</span><span class="p">,</span>
        <span class="n">max_policy_lipschitz</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Update PPO agent to minimize the PPO loss. (jitted function)</span>

<span class="sd">    :param env: Environment.</span>
<span class="sd">    :param args: Parameters for the PPO pretraining. (Note: these can differ from the global command line arguments)</span>
<span class="sd">    :param agent_state: AgentState (flax TrainState) object.</span>
<span class="sd">    :param storage: Storage storing data collected in episodes.</span>
<span class="sd">    :param max_policy_lipschitz: Limit on the policy Lipschitz constant, above which a cost is incurred.</span>
<span class="sd">    :param key: random number generator key</span>
<span class="sd">    :return:</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># Flatten collected experiences</span>
    <span class="n">b_obs</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">obs</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">state_space</span><span class="o">.</span><span class="n">gymspace</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">b_logprobs</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">logprobs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_actions</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">actions</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">b_advantages</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">advantages</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_returns</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">returns</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_values</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">ppo_loss</span><span class="p">(</span>
            <span class="n">agent_state</span><span class="p">:</span> <span class="n">AgentState</span><span class="p">,</span>
            <span class="n">params</span><span class="p">:</span> <span class="n">AgentParams</span><span class="p">,</span>
            <span class="n">obs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">act</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">logp</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">adv</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">ret</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">val</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">newlogprob</span><span class="p">,</span> <span class="n">entropy</span><span class="p">,</span> <span class="n">newvalue</span> <span class="o">=</span> <span class="n">get_action_and_value2</span><span class="p">(</span><span class="n">agent_state</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">act</span><span class="p">)</span>
        <span class="n">logratio</span> <span class="o">=</span> <span class="n">newlogprob</span> <span class="o">-</span> <span class="n">logp</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logratio</span><span class="p">)</span>

        <span class="c1"># Calculate how much policy is changing</span>
        <span class="n">approx_kl</span> <span class="o">=</span> <span class="p">((</span><span class="n">ratio</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">logratio</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Advantage normalization</span>
        <span class="n">adv</span> <span class="o">=</span> <span class="p">(</span><span class="n">adv</span> <span class="o">-</span> <span class="n">adv</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">adv</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>

        <span class="c1"># Policy loss</span>
        <span class="n">pg_loss1</span> <span class="o">=</span> <span class="o">-</span><span class="n">adv</span> <span class="o">*</span> <span class="n">ratio</span>
        <span class="n">pg_loss2</span> <span class="o">=</span> <span class="o">-</span><span class="n">adv</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">args</span><span class="o">.</span><span class="n">clip_coef</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">clip_coef</span><span class="p">)</span>
        <span class="n">pg_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">pg_loss1</span><span class="p">,</span> <span class="n">pg_loss2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Value loss</span>
        <span class="n">v_loss_unclipped</span> <span class="o">=</span> <span class="p">(</span><span class="n">newvalue</span> <span class="o">-</span> <span class="n">ret</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">v_clipped</span> <span class="o">=</span> <span class="n">val</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span>
            <span class="n">newvalue</span> <span class="o">-</span> <span class="n">val</span><span class="p">,</span>
            <span class="o">-</span><span class="n">args</span><span class="o">.</span><span class="n">clip_coef</span><span class="p">,</span>
            <span class="n">args</span><span class="o">.</span><span class="n">clip_coef</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">v_loss_clipped</span> <span class="o">=</span> <span class="p">(</span><span class="n">v_clipped</span> <span class="o">-</span> <span class="n">ret</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">v_loss_max</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">v_loss_unclipped</span><span class="p">,</span> <span class="n">v_loss_clipped</span><span class="p">)</span>
        <span class="n">v_loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">v_loss_max</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Entropy loss</span>
        <span class="n">entropy_loss</span> <span class="o">=</span> <span class="n">entropy</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Loss for lipschitz coefficient</span>
        <span class="n">lipschitz_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
            <span class="n">lipschitz_coeff</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;actor&#39;</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">weighted</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">cplip</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">linfty</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">max_policy_lipschitz</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># main loss as sum of each part loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">pg_loss</span> <span class="o">-</span> <span class="n">args</span><span class="o">.</span><span class="n">ent_coef</span> <span class="o">*</span> <span class="n">entropy_loss</span> <span class="o">+</span> <span class="n">v_loss</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">vf_coef</span> <span class="o">+</span> <span class="n">lipschitz_loss</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">pg_loss</span><span class="p">,</span> <span class="n">v_loss</span><span class="p">,</span> <span class="n">entropy_loss</span><span class="p">,</span> <span class="n">stop_gradient</span><span class="p">(</span><span class="n">approx_kl</span><span class="p">),</span> <span class="n">lipschitz_loss</span><span class="p">)</span>

    <span class="c1"># Create function that will return gradient of the specified function</span>
    <span class="n">ppo_loss_grad_fn</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">ppo_loss</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ppo_update_body</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Helper function for rollout, used to allow JAX jitting. </span>

<span class="sd">        :param i: step index</span>
<span class="sd">        :param val: tuple containing agent_state and collected experiences </span>
<span class="sd">        :return: updated tuple containing agent_state and collected experiences </span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="p">(</span><span class="n">agent_state</span><span class="p">,</span>
         <span class="n">b_obs</span><span class="p">,</span>
         <span class="n">b_actions</span><span class="p">,</span>
         <span class="n">b_logprobs</span><span class="p">,</span>
         <span class="n">b_advantages</span><span class="p">,</span>
         <span class="n">b_returns</span><span class="p">,</span>
         <span class="n">b_values</span><span class="p">,</span>
         <span class="n">b_inds_mat</span><span class="p">)</span> <span class="o">=</span> <span class="n">val</span>

        <span class="n">mb_inds</span> <span class="o">=</span> <span class="n">b_inds_mat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">_</span><span class="p">),</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">ppo_loss_grad_fn</span><span class="p">(</span>
            <span class="n">agent_state</span><span class="p">,</span>
            <span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
            <span class="n">b_obs</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
            <span class="n">b_actions</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
            <span class="n">b_logprobs</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
            <span class="n">b_advantages</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
            <span class="n">b_returns</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
            <span class="n">b_values</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="c1"># Update an agent</span>
        <span class="n">agent_state</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="n">grads</span><span class="p">)</span>

        <span class="n">val</span> <span class="o">=</span> <span class="p">(</span><span class="n">agent_state</span><span class="p">,</span>
               <span class="n">b_obs</span><span class="p">,</span>
               <span class="n">b_actions</span><span class="p">,</span>
               <span class="n">b_logprobs</span><span class="p">,</span>
               <span class="n">b_advantages</span><span class="p">,</span>
               <span class="n">b_returns</span><span class="p">,</span>
               <span class="n">b_values</span><span class="p">,</span>
               <span class="n">b_inds_mat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">val</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">update_epochs</span><span class="p">):</span>
        <span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">b_inds</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">independent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">iMax</span> <span class="o">=</span> <span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">//</span> <span class="n">args</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)</span>
        <span class="n">b_inds_mat</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">b_inds</span><span class="p">[:</span><span class="n">iMax</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">],</span> <span class="p">(</span><span class="n">iMax</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">))</span>

        <span class="n">val</span> <span class="o">=</span> <span class="p">(</span><span class="n">agent_state</span><span class="p">,</span>
               <span class="n">b_obs</span><span class="p">,</span>
               <span class="n">b_actions</span><span class="p">,</span>
               <span class="n">b_logprobs</span><span class="p">,</span>
               <span class="n">b_advantages</span><span class="p">,</span>
               <span class="n">b_returns</span><span class="p">,</span>
               <span class="n">b_values</span><span class="p">,</span>
               <span class="n">b_inds_mat</span><span class="p">)</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">fori_loop</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">iMax</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ppo_update_body</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="p">(</span><span class="n">agent_state</span><span class="p">,</span>
         <span class="n">b_obs</span><span class="p">,</span>
         <span class="n">b_actions</span><span class="p">,</span>
         <span class="n">b_logprobs</span><span class="p">,</span>
         <span class="n">b_advantages</span><span class="p">,</span>
         <span class="n">b_returns</span><span class="p">,</span>
         <span class="n">b_values</span><span class="p">,</span>
         <span class="n">b_inds_mat</span><span class="p">)</span> <span class="o">=</span> <span class="n">val</span>

        <span class="n">mb_inds</span> <span class="o">=</span> <span class="n">b_inds_mat</span><span class="p">[</span><span class="n">iMax</span><span class="p">]</span>
        <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">pg_loss</span><span class="p">,</span> <span class="n">v_loss</span><span class="p">,</span> <span class="n">entropy_loss</span><span class="p">,</span> <span class="n">approx_kl</span><span class="p">,</span> <span class="n">lipschitz_loss</span><span class="p">)),</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">ppo_loss_grad_fn</span><span class="p">(</span>
            <span class="n">agent_state</span><span class="p">,</span>
            <span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
            <span class="n">b_obs</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
            <span class="n">b_actions</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
            <span class="n">b_logprobs</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
            <span class="n">b_advantages</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
            <span class="n">b_returns</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
            <span class="n">b_values</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="c1"># Update an agent</span>
        <span class="n">agent_state</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="n">grads</span><span class="p">)</span>

    <span class="n">losses</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;Total loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
        <span class="s1">&#39;pg_loss&#39;</span><span class="p">:</span> <span class="n">pg_loss</span><span class="p">,</span>
        <span class="s1">&#39;v_loss&#39;</span><span class="p">:</span> <span class="n">v_loss</span><span class="p">,</span>
        <span class="s1">&#39;entropy_loss&#39;</span><span class="p">:</span> <span class="n">entropy_loss</span><span class="p">,</span>
        <span class="s1">&#39;approx_kl&#39;</span><span class="p">:</span> <span class="n">approx_kl</span><span class="p">,</span>
        <span class="s1">&#39;lipschitz_loss&#39;</span><span class="p">:</span> <span class="n">lipschitz_loss</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">agent_state</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">key</span></div>



<div class="viewcode-block" id="update_ppo">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.update_ppo">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">update_ppo</span><span class="p">(</span>
        <span class="n">env</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">PPOargs</span><span class="p">,</span>
        <span class="n">agent_state</span><span class="p">:</span> <span class="n">AgentState</span><span class="p">,</span>
        <span class="n">storage</span><span class="p">:</span> <span class="n">Storage</span><span class="p">,</span>
        <span class="n">max_policy_lipschitz</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Update PPO agent to minimize the PPO loss. </span>

<span class="sd">    :param env: Environment.</span>
<span class="sd">    :param args: Parameters for the PPO pretraining. (Note: these can differ from the global command line arguments)</span>
<span class="sd">    :param agent_state: AgentState (flax TrainState) object.</span>
<span class="sd">    :param storage: Storage storing data collected in episodes.</span>
<span class="sd">    :param max_policy_lipschitz: Limit on the policy Lipschitz constant, above which a cost is incurred.</span>
<span class="sd">    :param key: random number generator key</span>
<span class="sd">    :return:</span>
<span class="sd">       - agent_state: AgentState object. </span>
<span class="sd">       - loss: total loss</span>
<span class="sd">       - pg_loss: policy loss</span>
<span class="sd">       - v_loss: value loss</span>
<span class="sd">       - entropy_loss: entropy loss</span>
<span class="sd">       - approx_kl: approximate KL divergence</span>
<span class="sd">       - key: random number generator key</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># Flatten collected experiences</span>
    <span class="n">b_obs</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">obs</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">state_space</span><span class="o">.</span><span class="n">gymspace</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">b_logprobs</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">logprobs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_actions</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">actions</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">b_advantages</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">advantages</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_returns</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">returns</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_values</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">ppo_loss</span><span class="p">(</span>
            <span class="n">agent_state</span><span class="p">:</span> <span class="n">AgentState</span><span class="p">,</span>
            <span class="n">params</span><span class="p">:</span> <span class="n">AgentParams</span><span class="p">,</span>
            <span class="n">obs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">act</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">logp</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">adv</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">ret</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">val</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Loss function for the PPO pretraining. </span>

<span class="sd">        :param agent_state: AgentState (flax TrainState) object.</span>
<span class="sd">        :param params: Parameters of the </span>
<span class="sd">        :param obs: Observation.</span>
<span class="sd">        :param act: Action.</span>
<span class="sd">        :param logp: Log probability. </span>
<span class="sd">        :param adv: List of advantages. </span>
<span class="sd">        :param ret: List of returns (rewards). </span>
<span class="sd">        :param val: List of values. </span>
<span class="sd">        :return:</span>
<span class="sd">           - total loss</span>
<span class="sd">           - tuple containing the loss components</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="n">newlogprob</span><span class="p">,</span> <span class="n">entropy</span><span class="p">,</span> <span class="n">newvalue</span> <span class="o">=</span> <span class="n">get_action_and_value2</span><span class="p">(</span><span class="n">agent_state</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">act</span><span class="p">)</span>
        <span class="n">logratio</span> <span class="o">=</span> <span class="n">newlogprob</span> <span class="o">-</span> <span class="n">logp</span>
        <span class="n">logratio</span> <span class="o">=</span> <span class="n">newlogprob</span> <span class="o">-</span> <span class="n">logp</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logratio</span><span class="p">)</span>

        <span class="c1"># Calculate how much policy is changing</span>
        <span class="n">approx_kl</span> <span class="o">=</span> <span class="p">((</span><span class="n">ratio</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">logratio</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Advantage normalization</span>
        <span class="n">adv</span> <span class="o">=</span> <span class="p">(</span><span class="n">adv</span> <span class="o">-</span> <span class="n">adv</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">adv</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>

        <span class="c1"># Policy loss</span>
        <span class="n">pg_loss1</span> <span class="o">=</span> <span class="o">-</span><span class="n">adv</span> <span class="o">*</span> <span class="n">ratio</span>
        <span class="n">pg_loss2</span> <span class="o">=</span> <span class="o">-</span><span class="n">adv</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">args</span><span class="o">.</span><span class="n">clip_coef</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">clip_coef</span><span class="p">)</span>
        <span class="n">pg_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">pg_loss1</span><span class="p">,</span> <span class="n">pg_loss2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Value loss</span>
        <span class="n">v_loss_unclipped</span> <span class="o">=</span> <span class="p">(</span><span class="n">newvalue</span> <span class="o">-</span> <span class="n">ret</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">v_clipped</span> <span class="o">=</span> <span class="n">val</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span>
            <span class="n">newvalue</span> <span class="o">-</span> <span class="n">val</span><span class="p">,</span>
            <span class="o">-</span><span class="n">args</span><span class="o">.</span><span class="n">clip_coef</span><span class="p">,</span>
            <span class="n">args</span><span class="o">.</span><span class="n">clip_coef</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">v_loss_clipped</span> <span class="o">=</span> <span class="p">(</span><span class="n">v_clipped</span> <span class="o">-</span> <span class="n">ret</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">v_loss_max</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">v_loss_unclipped</span><span class="p">,</span> <span class="n">v_loss_clipped</span><span class="p">)</span>
        <span class="n">v_loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">v_loss_max</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Entropy loss</span>
        <span class="n">entropy_loss</span> <span class="o">=</span> <span class="n">entropy</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Loss for lipschitz coefficient</span>
        <span class="n">lipschitz_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
            <span class="n">lipschitz_coeff</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;actor&#39;</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">weighted</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">cplip</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">linfty</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">max_policy_lipschitz</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># main loss as sum of each part loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">pg_loss</span> <span class="o">-</span> <span class="n">args</span><span class="o">.</span><span class="n">ent_coef</span> <span class="o">*</span> <span class="n">entropy_loss</span> <span class="o">+</span> <span class="n">v_loss</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">vf_coef</span> <span class="o">+</span> <span class="n">lipschitz_loss</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">pg_loss</span><span class="p">,</span> <span class="n">v_loss</span><span class="p">,</span> <span class="n">entropy_loss</span><span class="p">,</span> <span class="n">stop_gradient</span><span class="p">(</span><span class="n">approx_kl</span><span class="p">))</span>

    <span class="c1"># Create function that will return gradient of the specified function</span>
    <span class="n">ppo_loss_grad_fn</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">ppo_loss</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">update_epochs</span><span class="p">):</span>
        <span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">b_inds</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">independent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">):</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">minibatch_size</span>
            <span class="n">mb_inds</span> <span class="o">=</span> <span class="n">b_inds</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
            <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">pg_loss</span><span class="p">,</span> <span class="n">v_loss</span><span class="p">,</span> <span class="n">entropy_loss</span><span class="p">,</span> <span class="n">approx_kl</span><span class="p">)),</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">ppo_loss_grad_fn</span><span class="p">(</span>
                <span class="n">agent_state</span><span class="p">,</span>
                <span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
                <span class="n">b_obs</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
                <span class="n">b_actions</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
                <span class="n">b_logprobs</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
                <span class="n">b_advantages</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
                <span class="n">b_returns</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
                <span class="n">b_values</span><span class="p">[</span><span class="n">mb_inds</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="c1"># Update an agent</span>
            <span class="n">agent_state</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="n">grads</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">agent_state</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">pg_loss</span><span class="p">,</span> <span class="n">v_loss</span><span class="p">,</span> <span class="n">entropy_loss</span><span class="p">,</span> <span class="n">approx_kl</span><span class="p">,</span> <span class="n">key</span></div>



<div class="viewcode-block" id="PPO">
<a class="viewcode-back" href="../../core.html#core.ppo_jax.PPO">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">PPO</span><span class="p">(</span><span class="n">env</span><span class="p">,</span>
        <span class="n">env_name</span><span class="p">,</span>
        <span class="n">cwd</span><span class="p">,</span>
        <span class="n">args</span><span class="p">,</span>
        <span class="n">max_policy_lipschitz</span><span class="p">,</span>
        <span class="n">neurons_per_layer</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span>
        <span class="n">activation_functions_jax</span><span class="o">=</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">],</span>
        <span class="n">activation_functions_txt</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="s1">&#39;relu&#39;</span><span class="p">],</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Function for PPO pretraining of policies. </span>

<span class="sd">    :param env: Environment.</span>
<span class="sd">    :param env_name: string, the name of the environment.</span>
<span class="sd">    :param cwd: Current working directory (used for saving the checkpoint). </span>
<span class="sd">    :param args: Parameters for the PPO pretraining. (Note: these can differ from the global command line arguments)</span>
<span class="sd">    :param max_policy_lipschitz: Limit on the policy Lipschitz constant, above which a cost is incurred.</span>
<span class="sd">    :param neurons_per_layer: List of ints, giving the number of neurons per layer. </span>
<span class="sd">    :param activation_functions_jax: List of flax activation functions. </span>
<span class="sd">    :param activation_functions_txt: List of strings, giving the name of the activation functions. </span>
<span class="sd">    :param verbose: If true, print more information. </span>
<span class="sd">    :return:</span>
<span class="sd">       - agent_state: AgentState object. </span>
<span class="sd">       - Policy_state: Policy network. </span>
<span class="sd">       - checkpoint_path: path to the saved checkpoint.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">max_policy_lipschitz</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">max_policy_lipschitz</span><span class="p">)</span>

    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">rng</span><span class="p">,</span> <span class="n">env_rng</span><span class="p">,</span> <span class="n">actor_key</span><span class="p">,</span> <span class="n">critic_key</span><span class="p">,</span> <span class="n">action_key</span><span class="p">,</span> <span class="n">permutation_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">env_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">env_rng</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span>

    <span class="n">obs</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">steps_since_reset</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">vreset</span><span class="p">(</span><span class="n">env_key</span><span class="p">)</span>

    <span class="c1"># Create both networks</span>
    <span class="n">actor</span> <span class="o">=</span> <span class="n">Actor</span><span class="p">(</span><span class="n">action_shape_prod</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">prod</span><span class="p">(),</span>
                  <span class="n">neurons_per_layer</span><span class="o">=</span><span class="n">neurons_per_layer</span><span class="p">,</span>
                  <span class="n">activation_func</span><span class="o">=</span><span class="n">activation_functions_jax</span><span class="p">)</span>  <span class="c1"># Declare prod out of class for JIT</span>
    <span class="n">critic</span> <span class="o">=</span> <span class="n">Critic</span><span class="p">(</span><span class="n">neurons_per_layer</span><span class="o">=</span><span class="n">neurons_per_layer</span><span class="p">,</span>
                    <span class="n">activation_func</span><span class="o">=</span><span class="n">activation_functions_jax</span><span class="p">)</span>

    <span class="c1"># Anneal learning rate over time</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">linear_schedule</span><span class="p">(</span><span class="n">count</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Anneal learning rate over time.</span>

<span class="sd">        :param count: Number of gradient updates performed so far.</span>
<span class="sd">        :return: Annealled learning rate. </span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="c1"># anneal learning rate linearly after one training iteration which contains</span>
        <span class="c1"># (args.num_minibatches * args.update_epochs) gradient updates</span>
        <span class="n">frac</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">count</span> <span class="o">//</span> <span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_minibatches</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">update_epochs</span><span class="p">))</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">num_iterations</span>
        <span class="k">return</span> <span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">frac</span>

    <span class="n">actor</span><span class="o">.</span><span class="n">apply</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">actor</span><span class="o">.</span><span class="n">apply</span><span class="p">)</span>
    <span class="n">critic</span><span class="o">.</span><span class="n">apply</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">critic</span><span class="o">.</span><span class="n">apply</span><span class="p">)</span>

    <span class="c1"># Initialize parameters of networks</span>
    <span class="n">agent_state</span> <span class="o">=</span> <span class="n">AgentState</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">apply_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">actor_fn</span><span class="o">=</span><span class="n">actor</span><span class="o">.</span><span class="n">apply</span><span class="p">,</span>
        <span class="n">critic_fn</span><span class="o">=</span><span class="n">critic</span><span class="o">.</span><span class="n">apply</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;actor&#39;</span><span class="p">:</span> <span class="n">actor</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">actor_key</span><span class="p">,</span> <span class="n">obs</span><span class="p">),</span> <span class="s1">&#39;critic&#39;</span><span class="p">:</span> <span class="n">critic</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">critic_key</span><span class="p">,</span> <span class="n">obs</span><span class="p">)},</span>
        <span class="n">tx</span><span class="o">=</span><span class="n">optax</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span>
            <span class="n">optax</span><span class="o">.</span><span class="n">clip_by_global_norm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">),</span>
            <span class="n">optax</span><span class="o">.</span><span class="n">inject_hyperparams</span><span class="p">(</span><span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">)(</span>  <span class="c1"># Or adamw optimizer???</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">linear_schedule</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">anneal_lr</span> <span class="k">else</span> <span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span>
            <span class="p">),</span>
        <span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># ALGO Logic: Storage setup</span>
    <span class="n">storage</span> <span class="o">=</span> <span class="n">Storage</span><span class="p">(</span>
        <span class="n">obs</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">state_space</span><span class="o">.</span><span class="n">gymspace</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
        <span class="n">actions</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
        <span class="n">logprobs</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)),</span>
        <span class="n">dones</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)),</span>
        <span class="n">values</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)),</span>
        <span class="n">advantages</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)),</span>
        <span class="n">returns</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)),</span>
        <span class="n">rewards</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)),</span>
    <span class="p">)</span>

    <span class="c1">### START OF MAIN LOOP ###</span>
    <span class="n">global_step</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">next_obs</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">steps_since_reset</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">vreset</span><span class="p">(</span><span class="n">env_key</span><span class="p">)</span>
    <span class="n">next_obs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_obs</span><span class="p">)</span>
    <span class="n">next_done</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>

    <span class="c1"># %%</span>

    <span class="n">steps_per_iteration</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">num_steps</span>

    <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Start iter </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">start_iter_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">action_key</span><span class="p">,</span> <span class="n">env_key</span> <span class="o">=</span> \
            <span class="n">rollout_jax_jit</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">agent_state</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">action_key</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span>
                            <span class="n">steps_since_reset</span><span class="p">)</span>
        <span class="n">time_diff</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;- Rollout done in  </span><span class="si">{</span><span class="p">(</span><span class="n">time_diff</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> [s] (</span><span class="si">{</span><span class="p">(</span><span class="n">steps_per_iteration</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">time_diff</span><span class="p">)</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1"> steps per second)&#39;</span><span class="p">)</span>

        <span class="c1"># Increment global number of steps</span>
        <span class="n">global_step</span> <span class="o">+=</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">num_steps</span>

        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="n">storage</span> <span class="o">=</span> <span class="n">compute_gae_jit</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">agent_state</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span><span class="p">,</span> <span class="n">storage</span><span class="p">)</span>

        <span class="n">agent_state</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">permutation_key</span> <span class="o">=</span> <span class="n">update_ppo_jit</span><span class="p">(</span>
            <span class="n">env</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">agent_state</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">max_policy_lipschitz</span><span class="p">,</span> <span class="n">permutation_key</span><span class="p">)</span>

        <span class="n">time_diff</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;- Policy update done in  </span><span class="si">{</span><span class="p">(</span><span class="n">time_diff</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> [s]&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-- Components of loss:&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">info</span> <span class="ow">in</span> <span class="n">losses</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;--- </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">info</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="n">lip_policy</span> <span class="o">=</span> <span class="n">lipschitz_coeff</span><span class="p">(</span><span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;actor&#39;</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">weighted</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">cplip</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">linfty</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;- Lipschitz coefficient (L1-norm) of policy network: </span><span class="si">{</span><span class="n">lip_policy</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- Total loss after iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">&#39;Total loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Calculate how good an approximation of the return is the value function</span>
        <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">storage</span><span class="o">.</span><span class="n">returns</span>
        <span class="n">var_y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="n">explained_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="k">if</span> <span class="n">var_y</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">/</span> <span class="n">var_y</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">speed</span> <span class="o">=</span> <span class="n">steps_per_iteration</span> <span class="o">/</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_iter_time</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39; - Speed of total iteration: </span><span class="si">{</span><span class="n">speed</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> steps per second&#39;</span><span class="p">)</span>

    <span class="c1"># %%</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

    <span class="n">len_traces</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">num_traces</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span>

    <span class="n">next_obs</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">steps_since_reset</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">vreset</span><span class="p">(</span><span class="n">env_key</span><span class="p">)</span>
    <span class="n">next_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_obs</span><span class="p">)</span>
    <span class="n">next_done</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span>

    <span class="n">obs_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">len_traces</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">state_space</span><span class="o">.</span><span class="n">gymspace</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">action_hist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">len_traces</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">len_traces</span><span class="p">):</span>
        <span class="n">global_step</span> <span class="o">+=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_envs</span>
        <span class="n">obs_plot</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">next_obs</span>

        <span class="c1"># Get action</span>
        <span class="n">action</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">actor_fn</span><span class="p">(</span><span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;actor&#39;</span><span class="p">],</span> <span class="n">next_obs</span><span class="p">)</span>

        <span class="n">action_hist</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">action</span>

        <span class="n">next_obs</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">steps_since_reset</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">infos</span> \
            <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">vstep</span><span class="p">(</span><span class="n">next_obs</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_get</span><span class="p">(</span><span class="n">action</span><span class="p">),</span> <span class="n">steps_since_reset</span><span class="p">)</span>
        <span class="n">next_done</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">)</span>

        <span class="n">next_obs</span><span class="p">,</span> <span class="n">next_done</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_obs</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_done</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_traces</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">obs_plot</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">obs_plot</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Trace&#39;</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">obs_plot</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:])</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;With actions&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">action_hist</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:])</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">====</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># Goal x-y limits</span>
    <span class="n">low</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">state_space</span><span class="o">.</span><span class="n">low</span>
    <span class="n">high</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">state_space</span><span class="o">.</span><span class="n">high</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">low</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">high</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">low</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">high</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Simulated traces under given controller&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">cwd</span><span class="p">,</span> <span class="s1">&#39;output&#39;</span><span class="p">,</span> <span class="s1">&#39;latest_ppo_traces.png&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>

    <span class="c1"># %%</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

    <span class="n">vectors_per_dim</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="n">sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectors_per_dim</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">state_space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>

    <span class="n">grid</span> <span class="o">=</span> <span class="n">define_grid</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">state_space</span><span class="o">.</span><span class="n">low</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">state_space</span><span class="o">.</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">sizes</span><span class="p">)</span>

    <span class="c1"># Get actions</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">actor_fn</span><span class="p">(</span><span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;actor&#39;</span><span class="p">],</span> <span class="n">grid</span><span class="p">)</span>

    <span class="n">key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">))</span>

    <span class="c1"># Make step</span>
    <span class="n">next_obs</span><span class="p">,</span> <span class="n">env_key</span><span class="p">,</span> <span class="n">steps_since_reset</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">infos</span> \
        <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">vstep</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">float64</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">high_precision</span> <span class="k">else</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">key</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span>
                    <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">int64</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">high_precision</span> <span class="k">else</span> <span class="n">jnp</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>

    <span class="n">scaling</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">vectors</span> <span class="o">=</span> <span class="p">(</span><span class="n">next_obs</span> <span class="o">-</span> <span class="n">grid</span><span class="p">)</span> <span class="o">*</span> <span class="n">scaling</span>

    <span class="c1"># Plot vectors</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="n">grid</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">grid</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">vectors</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">vectors</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">angles</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">)</span>

    <span class="c1"># Save figure</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">cwd</span><span class="p">,</span> <span class="s1">&#39;output&#39;</span><span class="p">,</span> <span class="s1">&#39;latest_ppo_vector.png&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>

    <span class="c1"># Return only the actor (not the rest of the agent)</span>
    <span class="n">Policy_neurons_per_layer</span> <span class="o">=</span> <span class="n">neurons_per_layer</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">low</span><span class="p">)]</span>
    <span class="n">Policy_act_funcs_jax</span> <span class="o">=</span> <span class="n">activation_functions_jax</span> <span class="o">+</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
    <span class="n">Policy_act_funcs_txt</span> <span class="o">=</span> <span class="n">activation_functions_txt</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;None&#39;</span><span class="p">]</span>

    <span class="c1"># Initialize policy network</span>
    <span class="n">policy_model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">Policy_neurons_per_layer</span><span class="p">,</span> <span class="n">Policy_act_funcs_jax</span><span class="p">)</span>
    <span class="n">Policy_state</span> <span class="o">=</span> <span class="n">create_train_state</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">policy_model</span><span class="p">,</span>
        <span class="n">act_funcs</span><span class="o">=</span><span class="n">Policy_act_funcs_jax</span><span class="p">,</span>
        <span class="n">rng</span><span class="o">=</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">in_dim</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">state_dim</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Load parameters from policy network initialized with PPO</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">Policy_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">Policy_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">][</span><span class="n">layer</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;actor&#39;</span><span class="p">][</span><span class="s1">&#39;params&#39;</span><span class="p">][</span><span class="n">layer</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span>
        <span class="n">Policy_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">][</span><span class="n">layer</span><span class="p">][</span><span class="s1">&#39;bias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">agent_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;actor&#39;</span><span class="p">][</span><span class="s1">&#39;params&#39;</span><span class="p">][</span><span class="n">layer</span><span class="p">][</span><span class="s1">&#39;bias&#39;</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;- Layer </span><span class="si">{</span><span class="n">layer</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Kernel:&#39;</span><span class="p">,</span> <span class="n">Policy_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">][</span><span class="n">layer</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">])</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Bias:&#39;</span><span class="p">,</span> <span class="n">Policy_state</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">][</span><span class="n">layer</span><span class="p">][</span><span class="s1">&#39;bias&#39;</span><span class="p">])</span>

    <span class="c1"># Save checkpoint of PPO state</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">_%H-%M-%S&quot;</span><span class="p">)</span>
    <span class="n">ckpt_export_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;ckpt/ppo_jax_</span><span class="si">{</span><span class="n">env_name</span><span class="si">}</span><span class="s2">_seed=</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">cwd</span><span class="p">,</span> <span class="n">ckpt_export_file</span><span class="p">)</span>

    <span class="c1"># Additional configuration info (stored in checkpoint)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">orbax_set_config</span><span class="p">(</span><span class="n">start_datetime</span><span class="o">=</span><span class="n">date</span><span class="p">,</span> <span class="n">env_name</span><span class="o">=</span><span class="n">env_name</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
                              <span class="n">RL_method</span><span class="o">=</span><span class="s2">&quot;PPO_JAX&quot;</span><span class="p">,</span> <span class="n">total_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span>
                              <span class="n">neurons_per_layer</span><span class="o">=</span><span class="n">Policy_neurons_per_layer</span><span class="p">,</span> <span class="n">activation_fn_txt</span><span class="o">=</span><span class="n">Policy_act_funcs_txt</span><span class="p">)</span>

    <span class="c1"># Checkpoint consists of policy state and config dictionary</span>
    <span class="n">ckpt</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="n">Policy_state</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">}</span>

    <span class="n">orbax_checkpointer</span> <span class="o">=</span> <span class="n">orbax</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">Checkpointer</span><span class="p">(</span><span class="n">orbax</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">PyTreeCheckpointHandler</span><span class="p">())</span>
    <span class="n">orbax_checkpointer</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">ckpt</span><span class="p">,</span>
                            <span class="n">save_args</span><span class="o">=</span><span class="n">flax</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">orbax_utils</span><span class="o">.</span><span class="n">save_args_from_target</span><span class="p">(</span><span class="n">ckpt</span><span class="p">),</span> <span class="n">force</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;- Export PPO checkpoint to file: </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">agent_state</span><span class="p">,</span> <span class="n">Policy_state</span><span class="p">,</span> <span class="n">checkpoint_path</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Thom Badings, Wietze Koops, Sebastian Junges, Nils Jansen.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>